{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256e3c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.9 (default, Jan 24 2021, 23:57:56) \\n[GCC 10.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2744ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the list of Test Runs in the testrun List --> Eval images will be created in root folder eval-images/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib\n",
    "\n",
    "#matplotlib.use(\"pgf\")\n",
    "#matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "#    'font.family': 'serif',\n",
    "#    'text.usetex': True,\n",
    "#    'pgf.rcfonts': False,\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfb425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ab7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_colors = {}\n",
    "get_counter_of_pid_list = []\n",
    "available_colors = ['g','r','c','m','y','k']*1000000\n",
    "\n",
    "def assign_color_to_hostname_pid(hostname, pid) -> str:\n",
    "    key = hostname + pid\n",
    "    if not key in dict_for_colors:\n",
    "        dict_for_colors[key] = available_colors[len(dict_for_colors)]\n",
    "    return dict_for_colors[key]\n",
    "\n",
    "def get_uid_of_ri(pid, hostname, accelerator) -> int:\n",
    "    key = str(pid) + str(hostname) + str(accelerator)\n",
    "    try:\n",
    "        val =  get_counter_of_pid_list.index(key)\n",
    "        return val\n",
    "    except Exception:\n",
    "        get_counter_of_pid_list.append(key)\n",
    "        return get_counter_of_pid_list.index(key)\n",
    "\n",
    "def accelerator_type_from_accelerator(acc) -> str:\n",
    "    if acc == \"mycpu\":\n",
    "        return \"cpu\"\n",
    "    if acc == \"0\" or acc == \"1\":\n",
    "        return \"gpu\"\n",
    "    if acc == \"main.py\": ## I don't understand this either\n",
    "        return \"vpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename): #data, trps, ps, images_folder, util\n",
    "\n",
    "    images_folder = \"../../../eval-images/\" + filename.split(\"_\")[2] +\"/\"\n",
    "\n",
    "    ps = filename.split(\"_\")\n",
    "    trps = dotdict({\n",
    "        'p0': int(ps[3])/1000,\n",
    "        'p0t': float(ps[4]),\n",
    "        'p1': int(ps[5])/1000,\n",
    "        'p2': int(ps[6])/1000,\n",
    "        \"p2t\": float(ps[7].replace(\".json\", \"\"))\n",
    "    })\n",
    "\n",
    "    with open(filename) as f:\n",
    "        d = json.load(f)\n",
    "    data = json_normalize(d)\n",
    "\n",
    "    failed = [end == -1 for end in data['end']]\n",
    "    data.insert(0, \"failed\", failed)\n",
    "\n",
    "    if data.start.min() != 0:\n",
    "        global experiment_start\n",
    "        experiment_start = data.start.min()\n",
    "\n",
    "    data.start = data.start - experiment_start\n",
    "    data.end = data.end - experiment_start\n",
    "    data['result.start_computation'] = data['result.start_computation'] - experiment_start\n",
    "    data['result.end_computation'] = data['result.end_computation'] - experiment_start\n",
    "    data['result.metadata.start'] = data['result.metadata.start'] - experiment_start\n",
    "    data['result.metadata.end'] = data['result.metadata.end'] - experiment_start\n",
    "\n",
    "    # End to End Latency\n",
    "    data.insert(0,\"rlat\",data.end - data.start)\n",
    "\n",
    "    # Distribution Latency - How long was it \n",
    "    data.insert(0, \"dlat\", data.rlat - data['result.metadata.inference_ms'])\n",
    "\n",
    "    data.insert(0, \"rfast\", data.rlat <= 10000)\n",
    "\n",
    "    data = data.loc[data['failed'] == False]\n",
    "\n",
    "    # (semi-)unique color per runtime instance\n",
    "    acc_color = [assign_color_to_hostname_pid(hostname, pid) for hostname,pid in zip(data['result.metadata.hostname'], data['result.pid'])]\n",
    "    data.insert(0,\"acc_color\", acc_color)\n",
    "\n",
    "    # unique id for every pid, starting with 0 (may be used as y-axis in some images)\n",
    "    inst_id = [get_uid_of_ri(pid, hn, acc) for pid,hn,acc in zip(data['result.pid'],data['result.metadata.hostname'],data['result.accelerator'])]\n",
    "    data.insert(0, \"inst_id\", inst_id)\n",
    "\n",
    "    # String that identifies the type of accelerator\n",
    "    acc_type = [accelerator_type_from_accelerator(acc) for acc in data['result.accelerator']]\n",
    "    data.insert(0, \"acc_type\", acc_type)\n",
    "\n",
    "    acc_name = [str(hn) + \"-\" + str(acc) for hn,acc in zip(data['result.metadata.hostname'], data['result.accelerator'])]\n",
    "    data.insert(0, \"acc_name\", acc_name)\n",
    "    \n",
    "    # Read the gpu+queue util as well\n",
    "    util = pd.read_pickle(ps[0] + \"_stats.pkl\")\n",
    "    util['time'] = util['time'] - experiment_start\n",
    "    experiment_dur = data['end'].max() * 1000\n",
    "    util = util.loc[util['time'] > 0]\n",
    "    util = util.loc[util['time'] < experiment_start + experiment_dur]\n",
    "\n",
    "    util['time'] = util['time']/1000 # convert to seconds\n",
    "    \n",
    "    return data, trps, ps, images_folder, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c69149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seconds(data, rstart=False):\n",
    "    # Plot by RStart\n",
    "    min, max = 0, 0\n",
    "    if rstart:\n",
    "        max = int(data.start.max() / 1000) # Rounds down to the latest second\n",
    "        min = 0 # Per definition for the start\n",
    "    else:\n",
    "        # Plot by EStart\n",
    "        max = int(data['result.start_computation'].max() / 1000)\n",
    "        min = int(data['result.start_computation'].min() / 1000)\n",
    "    data_smooth = data.rolling(1000, min_periods=1).mean()\n",
    "\n",
    "    seconds_d = {\n",
    "        # Request-Response Latency\n",
    "        'rlat_min': [],\n",
    "        'rlat_med': [],\n",
    "        'rlat_max': [],\n",
    "        # Execution Start-End Latency\n",
    "        'elat_min': [],\n",
    "        'elat_med': [],\n",
    "        'elat_max': [],\n",
    "        # Number of successful invocations\n",
    "        'rsuccess': [],\n",
    "        #'rfast_min': [],\n",
    "        'rfast_avg': [],\n",
    "        #'rfast_max': []\n",
    "    }\n",
    "\n",
    "    for i in range(min, max):\n",
    "        t_min = i * 1000\n",
    "        t_max = (i+1) * 1000\n",
    "        # For Host Selection:\n",
    "        # (data['result.metadata.hostname'] != 'sandybridge-ep') & \n",
    "        # Plot by RStart\n",
    "        curr, curr_smooth = {}, {}\n",
    "        if rstart:\n",
    "            curr = data.loc[(data.start >= t_min) & (data.start < t_max)]\n",
    "            curr_smooth = data_smooth.loc[(data.start >= t_min) & (data.start < t_max)]\n",
    "        else:\n",
    "        # Plot by EStart\n",
    "            curr = data.loc[(data['result.start_computation'] >= t_min) & (data['result.start_computation'] < t_max)]\n",
    "            curr_smooth = data_smooth.loc[(data['result.start_computation'] >= t_min) & (data['result.start_computation'] < t_max)]\n",
    "        seconds_d['rlat_min'].append(curr.rlat.min())\n",
    "        seconds_d['rlat_med'].append(curr.rlat.median())\n",
    "        seconds_d['rlat_max'].append(curr.rlat.max())\n",
    "\n",
    "        seconds_d['elat_min'].append(curr['result.metadata.inference_ms'].min())\n",
    "        seconds_d['elat_med'].append(curr['result.metadata.inference_ms'].median())\n",
    "        seconds_d['elat_max'].append(curr['result.metadata.inference_ms'].max())\n",
    "        \n",
    "        next10s = []\n",
    "        if rstart:\n",
    "            next10s = data.loc[(data.start >= t_min) & (data.start < t_min + 10000)]\n",
    "        else:\n",
    "        # Plot by EStart\n",
    "            next10s = data.loc[(data['result.start_computation'] >= t_min) & (data['result.start_computation'] < t_min+10000)]\n",
    "\n",
    "        #next10s = data.loc[(data.start >= t_min) & (data.start < t_min + 10000)]\n",
    "        seconds_d['rsuccess'].append(next10s.shape[0]/10)\n",
    "        #seconds_d['rfast_min'].append(next10s.loc[next10s['rfast']].min())\n",
    "        seconds_d['rfast_avg'].append(next10s.loc[next10s['rfast']].shape[0]/10)\n",
    "        #seconds_d['rfast_max'].append(next10s.loc[next10s['rfast']].max())\n",
    "\n",
    "    seconds = pd.DataFrame(seconds_d)\n",
    "    seconds_smooth = seconds.rolling(10, min_periods=1).mean()\n",
    "    return seconds, seconds_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e291119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seconds(data, xlim, latlim, reqlim, filename, opposing=False):\n",
    "    fig = plt.figure(figsize=(5.4, 3.6))\n",
    "    ax = plt.axes()\n",
    "    ax.set_ylabel(\"Latency [ms]\")\n",
    "    ax.set_xlabel(\"Time since start [s]\")\n",
    "    ax.set_ylim(latlim[0], latlim[1])\n",
    "    rlat = sns.lineplot(ax=ax, data=data, x=data.index, y='rlat_med', label=\"RLat\")\n",
    "    elat = sns.lineplot(ax=ax, data=data, x=data.index, y='elat_med', label=\"ELat\")\n",
    "    rlats = ax.fill_between(data.index, data['rlat_min'], data['rlat_max'], alpha=0.4)\n",
    "    elats = ax.fill_between(data.index, data['elat_max'], data['elat_min'], alpha=0.4)\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel(\"Requests/s [\\#]\")\n",
    "    ax2.set_ylim(reqlim[0], reqlim[1])\n",
    "    rsuc = sns.lineplot(ax=ax2, data=data, x=data.index, y='rsuccess', label=\"RSuccess\", color=\"darkgreen\", alpha=0.6)\n",
    "    rfast = sns.lineplot(ax=ax2, data=data, x=data.index, y='rfast_avg', label=\"RFast\", color=\"crimson\", alpha=0.6)\n",
    "    ##ax2.fill_between(x=data.index, y1=data['rfast_min'], y2=data['rfast_max'], alpha=0.4)\n",
    "    test  = sns.lineplot(ax=ax2, x=[0,trps.p0,trps.p0+trps.p1,trps.p0+trps.p1+trps.p2], y=[trps.p0t, trps.p0t, trps.p2t, trps.p2t], color=\"k\", label=\"Test plan\", alpha=0.6)\n",
    "    \n",
    "    # For the other way around\n",
    "    if opposing:\n",
    "        test2 = sns.lineplot(ax=ax2, x=[0,trps.p0,trps.p0+trps.p1,trps.p0+trps.p1+trps.p2], y=[trps.p2t, trps.p2t, trps.p0t, trps.p0t], color=\"dimgray\", label=\"Opp. test plan\", alpha=0.6)\n",
    "    \n",
    "    ax2.get_legend().remove()\n",
    "    #ax2.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    handles,labels = [],[]\n",
    "    for ax in fig.axes:\n",
    "        for h,l in zip(*ax.get_legend_handles_labels()):\n",
    "            handles.append(h)\n",
    "            labels.append(l)\n",
    "\n",
    "    plt.legend(handles,labels, loc='upper left')\n",
    "\n",
    "    #plt.legend()#bbox_to_anchor=(1, 1), borderaxespad=0) #loc=\"upper right\")#,\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(xlim)\n",
    "    plt.savefig(images_folder + filename, dpi=1200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_computation(data, color, xlim, filename):\n",
    "    ax = plt.axes()\n",
    "    ax.set_ylabel(\"Runtime ID [\\#]\")\n",
    "    ax.set_xlabel(\"Time since start [s]\")\n",
    "    plt.hlines(y=data.inst_id, xmin=data['result.start_computation']/1000, xmax=data['result.end_computation']/1000, colors=color, linestyle=\"solid\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(xlim)\n",
    "    plt.savefig(images_folder + filename, dpi=1200)\n",
    "    plt.close()\n",
    "    \n",
    "def plot_dual_computation(onnx, onnx2, xlim, filename):\n",
    "    ax = plt.axes()\n",
    "    ax.set_ylabel(\"Runtime ID [\\#]\")\n",
    "    ax.set_xlabel(\"Time since start [s]\")\n",
    "    plt.hlines(y=onnx.inst_id, xmin=onnx['result.start_computation']/1000, xmax=onnx['result.end_computation']/1000, colors=\"g\", linestyle=\"solid\", label=\"Rising workload\")\n",
    "    plt.hlines(y=onnx2.inst_id, xmin=onnx2['result.start_computation']/1000, xmax=onnx2['result.end_computation']/1000, colors=\"r\", linestyle=\"solid\", label=\"Falling workload\")\n",
    "    \n",
    "    #ax.get_legend().remove()\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.xlim(xlim)\n",
    "    plt.savefig(images_folder + filename, dpi=1200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_gpu_queue(util, endpoint, xlim, reqlim, a1, a2, b1, gpuf, queuef, opposing=False):\n",
    "    rolling = util[0:endpoint].rolling(30, min_periods=1).mean()\n",
    "    \n",
    "    # allGPU\n",
    "    fig = plt.figure(figsize=(5.4, 3.6))\n",
    "    ax = plt.axes()\n",
    "    ax.set_ylabel(\"GPU Utilization [%]\")\n",
    "    ax.set_ylim(0, 101)\n",
    "\n",
    "    if a1:\n",
    "        sns.lineplot(ax=ax,data=rolling, x='time', y='util_gpu1', label=\"A-1\")\n",
    "    if a2:\n",
    "        sns.lineplot(ax=ax,data=rolling, x='time', y='util_gpu2', label=\"A-2\")\n",
    "    if b1:\n",
    "        sns.lineplot(ax=ax,data=rolling, x='time', y='util_gpu3', label=\"B-1\")\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel(\"Requests/s [\\#]\")\n",
    "    ax2.set_ylim(reqlim[0], reqlim[1])\n",
    "    sns.lineplot(ax=ax2,x=[0,trps.p0,trps.p0+trps.p1,trps.p0+trps.p1+trps.p2], y=[trps.p0t, trps.p0t, trps.p2t, trps.p2t], color=\"black\", label=\"Test plan\")\n",
    "\n",
    "    # For the other way around\n",
    "    if opposing:\n",
    "        test2 = sns.lineplot(ax=ax2, x=[0,trps.p0,trps.p0+trps.p1,trps.p0+trps.p1+trps.p2], y=[trps.p2t, trps.p2t, trps.p0t, trps.p0t], color=\"dimgray\", label=\"Opp. test plan\", alpha=0.6)\n",
    "    \n",
    "    \n",
    "    handles,labels = [],[]\n",
    "    for ax in fig.axes:\n",
    "        for h,l in zip(*ax.get_legend_handles_labels()):\n",
    "            handles.append(h)\n",
    "            labels.append(l)\n",
    "\n",
    "    plt.legend(handles,labels, loc='upper left')\n",
    "    plt.xlim(xlim)\n",
    "\n",
    "    plt.savefig(images_folder + gpuf, dpi=1200)\n",
    "    plt.close()\n",
    "\n",
    "    ############################################\n",
    "    fig = plt.figure(figsize=(5.4, 3.6))\n",
    "    ax = plt.axes()\n",
    "    ax.set_ylabel(\"Queued Invocations [\\#]\")\n",
    "\n",
    "    sns.lineplot(ax=ax,data=rolling, x='time', y='queued', label=\"Queued invocations\")\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel(\"Requests/s [\\#]\")\n",
    "    ax2.set_ylim(reqlim[0], reqlim[1])\n",
    "    sns.lineplot(ax=ax2,x=[0,trps.p0,trps.p0+trps.p1,trps.p0+trps.p1+trps.p2], y=[trps.p0t, trps.p0t, trps.p2t, trps.p2t], color=\"black\", label=\"Test plan\")\n",
    "    # For the other way around\n",
    "    if opposing:\n",
    "        test2 = sns.lineplot(ax=ax2, x=[0,trps.p0,trps.p0+trps.p1,trps.p0+trps.p1+trps.p2], y=[trps.p2t, trps.p2t, trps.p0t, trps.p0t], color=\"dimgray\", label=\"Opp. test plan\", alpha=0.6)\n",
    "    \n",
    "    handles,labels = [],[]\n",
    "    for ax in fig.axes:\n",
    "        for h,l in zip(*ax.get_legend_handles_labels()):\n",
    "            handles.append(h)\n",
    "            labels.append(l)\n",
    "\n",
    "    plt.legend(handles,labels, loc='upper left')\n",
    "    plt.xlim(xlim)\n",
    "\n",
    "    plt.savefig(images_folder + queuef, dpi=1200)\n",
    "    plt.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fd2576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRun():\n",
    "    def __init__(self, rfast_end, xlim, latlim, reqlim, latlimp0, latlimlo, filename, double=False):\n",
    "        self.rfast_end = rfast_end\n",
    "        self.xlim = xlim\n",
    "        self.latlim = latlim\n",
    "        self.reqlim  =reqlim\n",
    "        self.latlimp0 = latlimp0 \n",
    "        self.latlimlo = latlimlo\n",
    "        self.filename = filename\n",
    "        self.data, self.trps, self.ps, self.images_folder, self.util = load_data(filename)\n",
    "        self.seconds, self.seconds_smooth = generate_seconds(self.data)\n",
    "        self.double = double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56ff1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format=png\n",
      "Round=0, Run=../../../long-results/2021-08-02T15:36:25_inv_singleServerSingleGPU_120000_0.5_600000_120000_2.5.json\n",
      "Round=1, Run=../../../long-results/2021-08-02T16:09:09_inv_singleServerAllGPU_120000_1.0_600000_120000_4.0.json\n",
      "Round=2, Run=../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPUForDual_120000_1.0_600000_120000_5.0.json\n",
      "Round=3, Run=../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPU_120000_1.0_600000_120000_5.0.json\n",
      "Round=4, Run=../../../long-results/2021-07-03T21:00:21_inv_allIhave_120000_10_600000_120000_24.json\n",
      "Round=5, Run=../../../long-results/2021-07-19T19:18:05_inv_allIhaveDoubleBetter_120000_5.0_600000_120000_10.0.json\n",
      "Format=pgf\n",
      "Round=0, Run=../../../long-results/2021-08-02T15:36:25_inv_singleServerSingleGPU_120000_0.5_600000_120000_2.5.json\n",
      "Round=1, Run=../../../long-results/2021-08-02T16:09:09_inv_singleServerAllGPU_120000_1.0_600000_120000_4.0.json\n",
      "Round=2, Run=../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPUForDual_120000_1.0_600000_120000_5.0.json\n",
      "Round=3, Run=../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPU_120000_1.0_600000_120000_5.0.json\n",
      "Round=4, Run=../../../long-results/2021-07-03T21:00:21_inv_allIhave_120000_10_600000_120000_24.json\n",
      "Round=5, Run=../../../long-results/2021-07-19T19:18:05_inv_allIhaveDoubleBetter_120000_5.0_600000_120000_10.0.json\n",
      "Format=pdf\n",
      "Round=0, Run=../../../long-results/2021-08-02T15:36:25_inv_singleServerSingleGPU_120000_0.5_600000_120000_2.5.json\n",
      "Round=1, Run=../../../long-results/2021-08-02T16:09:09_inv_singleServerAllGPU_120000_1.0_600000_120000_4.0.json\n",
      "Round=2, Run=../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPUForDual_120000_1.0_600000_120000_5.0.json\n",
      "Round=3, Run=../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPU_120000_1.0_600000_120000_5.0.json\n",
      "Round=4, Run=../../../long-results/2021-07-03T21:00:21_inv_allIhave_120000_10_600000_120000_24.json\n",
      "Round=5, Run=../../../long-results/2021-07-19T19:18:05_inv_allIhaveDoubleBetter_120000_5.0_600000_120000_10.0.json\n"
     ]
    }
   ],
   "source": [
    "testruns = [\n",
    "    TestRun(420,[0, 1050],[0, 200_000],[0,5.1],[0, 10_000],[0, 10_000],\"../../../long-results/2021-08-02T15:36:25_inv_singleServerSingleGPU_120000_0.5_600000_120000_2.5.json\"),\n",
    "    TestRun(520,[0, 1050],[0, 200_000],[0,5.1],[0, 10_000],[0, 10_000],\"../../../long-results/2021-08-02T16:09:09_inv_singleServerAllGPU_120000_1.0_600000_120000_4.0.json\"),\n",
    "    TestRun(620,[0, 1050],[0, 200_000],[0,5.1],[0, 10_000],[0, 10_000],\"../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPUForDual_120000_1.0_600000_120000_5.0.json\"),\n",
    "    # rename folder!\n",
    "    TestRun(620,[0, 850],[0, 70_000],[0,25],[0, 8_100],[0, 10_000],\"../../../long-results/2021-07-13T16:54:46_inv_singleServerAllVPU_120000_1.0_600000_120000_5.0.json\"),\n",
    "    TestRun(530,[0, 850],[0, 70_000],[0,25],[0, 8_100],[0, 10_000],\"../../../long-results/2021-07-03T21:00:21_inv_allIhave_120000_10_600000_120000_24.json\"),\n",
    "    TestRun(600,[0, 850],[0, 20_000],[0,20],[0, 8_100],[0, 10_000],\"../../../long-results/2021-07-19T19:18:05_inv_allIhaveDoubleBetter_120000_5.0_600000_120000_10.0.json\", True),\n",
    "]\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "for suffix in [\"png\", \"pgf\", \"pdf\"]:\n",
    "    print(f'Format={suffix}')\n",
    "\n",
    "    for idx, run in enumerate(testruns):\n",
    "        print(f'Round={idx}, Run={run.filename}')\n",
    "        global trps\n",
    "        trps = run.trps\n",
    "        global images_folder\n",
    "        images_folder = run.images_folder\n",
    "        # Seconds parameters:\n",
    "        # data, xlim, latlim, reqlim, filename, opposing=False\n",
    "        # Normal Seconds\n",
    "        plot_seconds(run.seconds, run.xlim, run.latlim, run.reqlim, \"latency.\" + suffix)\n",
    "        plot_seconds(run.seconds_smooth, run.xlim, run.latlim, run.reqlim, \"latency_smooth.\" + suffix)\n",
    "\n",
    "        # RFast\n",
    "    \n",
    "        plot_seconds(run.seconds_smooth.iloc[0:run.rfast_end], [0, run.rfast_end], run.latlimlo, run.reqlim, \"latency_untillost_smooth.\" + suffix)\n",
    "\n",
    "        # P0\n",
    "        plot_seconds(run.seconds_smooth.iloc[0:120], [0, 120], run.latlimp0, run.reqlim, \"latency_p0_smooth.\" + suffix)\n",
    "\n",
    "        # GPU+Queue\n",
    "        # enpoint is xlim, how does this look?\n",
    "        # util, endpoint, xlim, reqlim, a1, a2, b1, gpuf, queuef, opposing=False)\n",
    "        hasa2 = run.rfast_end > 421\n",
    "        hasb1 = run.rfast_end == 530 or run.rfast_end == 600\n",
    "        plot_gpu_queue(run.util, run.xlim[1], run.xlim, run.reqlim, True, hasa2, hasb1, \"gpu.\" + suffix, \"queue.\" + suffix)\n",
    "\n",
    "        # Invocations    \n",
    "        if run.double:\n",
    "            onnx = run.data.loc[run.data['inv.runtime'] == 'onnx']\n",
    "            onnx2 = run.data.loc[run.data['inv.runtime'] == 'onnx2']\n",
    "            plot_dual_computation(onnx, onnx2, run.xlim, \"invocations_runtimes_opp.\" + suffix)\n",
    "            seconds_o, seconds_smooth_o = generate_seconds(onnx)\n",
    "            seconds_o2, seconds_smooth_o2 = generate_seconds(onnx2)\n",
    "            plot_seconds(seconds_smooth_o, run.xlim, run.latlim, run.reqlim,\"latency_smooth_o1.\" + suffix, True)\n",
    "            plot_seconds(seconds_smooth_o2, run.xlim, run.latlim, run.reqlim, \"latency_smooth_o2.\" + suffix, True)\n",
    "        else:\n",
    "            plot_computation(run.data, run.data['acc_color'], run.xlim, \"invocations_runtimes.\" + suffix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cca883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba295e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "jupyter-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}